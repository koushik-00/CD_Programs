{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koushik-00/CD_Programs/blob/main/DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex-1: Implementation of classification using MLP**"
      ],
      "metadata": {
        "id": "fHvGjNJyf4bh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK0WghZYfy_X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist.data, mnist.target.astype(int)\n",
        "\n",
        "X /= 255.0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter = 10, random_state=42)\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "predictions = mlp.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_test, predictions))\n",
        "\n",
        "plt.figure(figsize = (10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex-2: Understanding of Deep learning Packages Basics: Tensorflow,\n",
        "Keras, Theano and PyTorch.**"
      ],
      "metadata": {
        "id": "PBCgiRzCjfzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow theano torch"
      ],
      "metadata": {
        "id": "urfsizmGj22A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "model = tf.keras.Sequential([\n",
        "tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "tf.keras.layers.Dense(128, activation='relu'),\n",
        "tf.keras.layers.Dropout(0.2),\n",
        "tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n",
        "\n",
        "!pip install --upgrade numpy==1.20.3\n",
        "import numpy as np\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "\n",
        "x = T.dscalar('x')\n",
        "y = T.dscalar('y')\n",
        "z = x + y\n",
        "\n",
        "addition = theano.function([x, y], z)\n",
        "\n",
        "result = addition(2.5, 3.7)\n",
        "print(\"Result:\", result)\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "t1=torch.tensor([1, 2, 3, 4])\n",
        "t2=torch.tensor([[1, 2, 3, 4],\n",
        "[5, 6, 7, 8],\n",
        "[9, 10, 11, 12]])\n",
        "\n",
        "print(\"Tensor t1: \\n\", t1)\n",
        "print(\"\\nTensor t2: \\n\", t2)\n",
        "\n",
        "print(\"\\nRank of t1: \", len(t1.shape))\n",
        "print(\"Rank of t2: \", len(t2.shape))\n",
        "\n",
        "print(\"\\nRank of t1: \", t1.shape)\n",
        "print(\"Rank of t2: \", t2.shape)"
      ],
      "metadata": {
        "id": "zY-JTR-ciELq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install theano"
      ],
      "metadata": {
        "id": "cOXCV3JCoAlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex-3: Improve the performance of Deep learning models with Hyper-Parameter Tuning.**"
      ],
      "metadata": {
        "id": "ETKstcn3krI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "ON7ZvRycq4kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def create_model(learning_rate=0.01, num_units=64):\n",
        "  model = keras.Sequential([\n",
        "  keras.layers.Dense(units=num_units, activation='relu',\n",
        "  input_shape=(X_train.shape[1],)),\n",
        "  keras.layers.Dense(units=num_units, activation='relu'),\n",
        "  keras.layers.Dense(units=3, activation='softmax') # Multi-class classification\n",
        "  ])\n",
        "  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=5, batch_size=10)\n",
        "# layers = [[32], (64, 32), (128, 64, 32)]\n",
        "\n",
        "param_grid = dict(\n",
        "learning_rate = [0.001, 0.01, 0.1],\n",
        "num_units = [32, 64, 128])\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid = param_grid, cv=3, verbose=1)\n",
        "grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best Parameters: {grid_result.best_params_}\")\n",
        "print(f\"Best Accuracy: {grid_result.best_score_}\")\n",
        "\n",
        "best_model = grid_result.best_estimator_.model\n",
        "best_model.fit(X_train, y_train, epochs=30, batch_size=32)\n",
        "\n",
        "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "xkoz8ogpp6d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex-4: Optimization techniques of Gradient Descent(GD),Momentum Based GD,Nesterov Accelerated GD,Stochastic GD,AdaGrad,RMSProp,Adam**"
      ],
      "metadata": {
        "id": "MfJ0c23C0Jlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "def create_model(optimizer):\n",
        "  model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer,\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "optimizers = {\n",
        "'SGD': tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "'Momentum': tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "'Nesterov': tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
        "'AdaGrad': tf.keras.optimizers.Adagrad(learning_rate=0.01),\n",
        "'RMSProp': tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "'Adam': tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "}\n",
        "\n",
        "accuracy_history = {}\n",
        "\n",
        "num_epochs = 5\n",
        "for optimizer_name, optimizer in optimizers.items():\n",
        "  model = create_model(optimizer)\n",
        "  history = model.fit(X_train, y_train, epochs=num_epochs, verbose=1,\n",
        "  validation_data=(X_test, y_test))\n",
        "  accuracy_history[optimizer_name] = history.history['accuracy']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for optimizer_name, accuracy_values in accuracy_history.items():\n",
        "  plt.plot(accuracy_values, label=optimizer_name)\n",
        "plt.title('Accuracy Curves for Different Optimizers')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VKQqQKlCuyxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex-5: Implementing of Denoising, sparse and contractive autoencoders.**"
      ],
      "metadata": {
        "id": "CrC1CfgZ7uty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "plt.show()\n",
        "\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "num_pixels = X_train.shape[0] * X_train.shape[1]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "\n",
        "noise_factor = 0.2\n",
        "x_train_noisy = X_train + noise_factor * numpy.random.normal(loc=0.0, scale=1.0 , size=X_train.shape)\n",
        "x_test_noisy = X_test + noise_factor * numpy.random.normal(loc=0.0, scale=1.0, size=X_test.shape)\n",
        "x_train_noisy = numpy.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = numpy.clip(x_test_noisy, 0., 1.)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=num_pixels, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(300, activation='relu'))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(784, activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "model.fit(x_train_noisy, X_train, validation_data=(x_test_noisy, X_test), epochs=2 , batch_size=200)\n",
        "\n",
        "pred = model.predict(x_test_noisy)\n",
        "pred.shape\n",
        "X_test.shape\n",
        "\n",
        "X_test = numpy.reshape(X_test, (10000,28,28)) * 255\n",
        "pred = numpy.reshape(pred, (10000,28,28)) *255\n",
        "x_test_noisy = numpy.reshape(x_test_noisy, (-1,28,28)) *255\n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Test Images\")\n",
        "\n",
        "for i in range(10,20,1):\n",
        "  plt.subplot(2, 10, i+1)\n",
        "  plt.imshow(X_test[i,:,:], cmap='gray')\n",
        "curr_lbl = y_test[i]\n",
        "plt.title(\"(Label: \" + str(curr_lbl) + \")\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Test Images with Noise\")\n",
        "for i in range(10,20,1):\n",
        "  plt.subplot(2, 10, i+1)\n",
        "  plt.imshow(x_test_noisy[i,:,:], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "print(\"Reconstruction of Noisy Test Images\")\n",
        "for i in range(10,20,1):\n",
        "  plt.subplot(2, 10, i+1)\n",
        "  plt.imshow(pred[i,:,:], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cxMIisga0hme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ex-6: performance of the model using various Regularization Techniques.**"
      ],
      "metadata": {
        "id": "dKoZ--0E9TRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()\n",
        "X_train\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "X_train_flat = X_train.reshape(len(X_train), 28*28)\n",
        "X_test_flat = X_test.reshape(len(X_test), 28*28)\n",
        "X_train_flat.shape\n",
        "\n",
        "model=keras.Sequential([\n",
        "keras.layers.Dense(10,input_shape=(784,),activation='sigmoid')])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_flat,y_train,epochs=5)\n",
        "model.evaluate(X_test_flat,y_test)\n",
        "y_pred=model.predict(X_test_flat)\n",
        "y_pred[0]\n",
        "\n",
        "y_pred_labels=[np.argmax(i) for i in y_pred]\n",
        "cm = tf.math.confusion_matrix(labels=y_test,predictions=y_pred_labels)\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm,annot=True,fmt='d')\n",
        "\n",
        "from keras import regularizers\n",
        "model1=keras.Sequential([\n",
        "  keras.layers.Dense(100,input_shape=(784,),activation='relu',kernel_regularizer=regularizers.l2 (0.0001)),\n",
        "  keras.layers.Dense(10,activation='sigmoid')])\n",
        "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model1.fit(X_train_flat,y_train,epochs=5)\n",
        "model1.evaluate(X_test_flat, y_test)\n",
        "\n",
        "model2=keras.Sequential([\n",
        "  keras.layers.Dense(100,input_shape=(784,),activation='relu',kernel_regularizer=regularizers.l1 (0.0001)),\n",
        "  keras.layers.Dense(10,activation='sigmoid')\n",
        "])\n",
        "model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.fit(X_train_flat,y_train,epochs=5)\n",
        "\n",
        "model2.evaluate(X_test_flat,y_test)\n",
        "\n",
        "from keras.layers import Dropout\n",
        "model3=keras.Sequential([\n",
        "  keras.layers.Dense(100,input_shape=(784,),activation='relu'),\n",
        "  Dropout(0.25),\n",
        "  keras.layers.Dense(10,activation='sigmoid')\n",
        "])\n",
        "model3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.fit(X_train_flat,y_train,epochs=5)\n",
        "model3.evaluate(X_test_flat,y_test)\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "model3.fit(X_train_flat,y_train,epochs=5,callbacks = [EarlyStopping(monitor='val_acc', patience =2)])\n",
        "model3.evaluate(X_test_flat,y_test)"
      ],
      "metadata": {
        "id": "5Mkni1I69Cao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}